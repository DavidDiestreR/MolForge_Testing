{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8ea5d0",
   "metadata": {},
   "source": [
    "# MolForge Evaluation Playground (RDKit + MolForge)\n",
    "\n",
    "Notebook modular i executable per\n",
    "- **rebre SMILES** (p. ex. de CoCoGraph),\n",
    "- **convertir-los a fingerprints** amb RDKit,\n",
    "- **decodificar amb MolForge** (fingerprint → SMILES/SELFIES), i\n",
    "- **avaluar** amb les **mètriques** que es fan servir al paper de MolForge.\n",
    "\n",
    "**Comentaris del codi en anglès** per claredat; explicacions i instruccions en català/castellà.\n",
    "\n",
    "---\n",
    "### Assumpcions de l'entorn\n",
    "- **Entorn creat via `environment.yml`**\n",
    "- **RDKit i MolForge** ja disponibles (instal·lats via `environment.yml` + pip GitHub).\n",
    "- No cal clonar MolForge: s'ha instal·lat directament des de GitHub.\n",
    "- (Opcional) **SELFIES** ja inclòs al `environment.yml`.\n",
    "\n",
    "Aquest notebook inclou un **mode demo** opcional: simula prediccions perquè puguis executar-lo i veure la mètrica. \n",
    "Quan tinguis MolForge preparat, desactiva el `DEMO_MODE` a la secció d'Input i omple `MOLFORGE_CHECKPOINT`/`MODEL_NAME`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee48d0d",
   "metadata": {},
   "source": [
    "## 0) Device — detección automática CPU/GPU\n",
    "<small>El entorno ya está preparado con `environment.yml`. Aquí detectamos el **device** automáticamente. Puedes forzarlo con `preferred=\"cpu\"` o mediante variable de entorno `DEVICE`.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e123b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Device detection (import from src if available; otherwise define here)\n",
    "try:\n",
    "    from src.utils_device import pick_device  # prefer project utility if present\n",
    "except Exception:\n",
    "    def pick_device(preferred: str | None = None) -> str:\n",
    "        \"\"\"Return 'cuda', 'mps' (Apple), or 'cpu'. Supports override with preferred.\"\"\"\n",
    "        if preferred in {\"cpu\", \"cuda\", \"mps\"}:\n",
    "            return preferred\n",
    "        try:\n",
    "            import torch\n",
    "        except Exception:\n",
    "            return \"cpu\"\n",
    "        try:\n",
    "            if torch.cuda.is_available():\n",
    "                return \"cuda\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            import torch\n",
    "            if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "                return \"mps\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        return \"cpu\"\n",
    "\n",
    "import os\n",
    "device = pick_device(os.getenv(\"DEVICE\"))  # set DEVICE=cpu|cuda|mps to override\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f4c8c4",
   "metadata": {},
   "source": [
    "## Sobre el 'sesgo' a l'avaluació\n",
    "Tu vols **avaluar un model ja entrenat** amb molècules qualsevol. Perfecte. El que anomenem aquí 'sesgo de mètrica' **no té a veure** amb com s'ha entrenat el model, sinó amb **com mesurem la similitud**.\n",
    "- Diferents fingerprints tenen **escales de Tc** diferents. Si només uses **una** huella per avaluar, el número pot semblar més alt/baix només per l'escala d'aquella huella.\n",
    "- Per això el paper mostra **multi-fingerprint** i un **llindar CDF p=0.01**: perquè les lectures siguin més comparables entre representacions. \n",
    "- **No és obligatori**. Aquí et dono **totes les mètriques**, i tu pots activar/desactivar l'avaluació multi-fingerprint segons et convingui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d24f3f",
   "metadata": {},
   "source": [
    "## 1) Input — Paràmetres i SMILES de prova\n",
    "Edita aquesta cel·la per escollir fingerprints, sortida, checkpoints, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9aa721",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# INPUT SECTION (edit here)\n",
    "# ==============================\n",
    "\n",
    "# --- Dummy SMILES (real molecules) to let you run the notebook immediately ---\n",
    "SMILES_LIST = [\n",
    "    \"CCO\",                       # ethanol\n",
    "    \"c1ccccc1\",                  # benzene\n",
    "    \"CC(=O)OC1=CC=CC=C1C(=O)O\",  # aspirin\n",
    "    \"CN1C=NC2=C1C(=O)N(C(=O)N2)C\",  # caffeine\n",
    "    \"CC(=O)O\",                   # acetic acid\n",
    "]\n",
    "\n",
    "# --- Fingerprint used as *input* to MolForge (choose one) ---\n",
    "# Common: 'ECFP4', 'AEs', 'TT', 'HashAP', 'RDK4', 'MACCS', 'FCFP4', etc.\n",
    "INPUT_FP = \"ECFP4\"\n",
    "\n",
    "# --- Output representation from MolForge ---\n",
    "# 'SMILES' or 'SELFIES' (SELFIES avoids invalid strings but you need selfies installed)\n",
    "OUTPUT_REPR = \"SMILES\"\n",
    "\n",
    "# --- Multi-fingerprint evaluation (recommended but optional) ---\n",
    "# If True, we compute Tc with a panel of ~15 fingerprints; if False, we only use a single eval FP.\n",
    "USE_MULTI_FP = True\n",
    "\n",
    "# --- If not using multi-fp, pick a single eval fingerprint for Tc ---\n",
    "SINGLE_EVAL_FP = \"ECFP4\"\n",
    "\n",
    "# --- MolForge model config (fill when you have the real repo installed) ---\n",
    "MODEL_NAME = \"ecfp4_to_smiles\"       # adapt to your MolForge model naming\n",
    "MOLFORGE_CHECKPOINT = \"/path/to/molforge_ckpt.pt\"  # <-- put your real path here\n",
    "\n",
    "# --- Device for MolForge ('cuda' or 'cpu') ---\n",
    "\n",
    "# --- Tokenizer vocab for sparse modes (AEs/TT) if your MolForge needs it ---\n",
    "TOKENIZER_VOCAB_JSON = None\n",
    "\n",
    "# --- Bit length for hashed fingerprints (used for ECFP/FCFP/HashAP/HashTT/RDK4/Pattern/Layered) ---\n",
    "HASHED_NBITS = 2048\n",
    "\n",
    "# --- DEMO MODE: If True, no real MolForge is required. A DummyDecoder will echo canonical SMILES.\n",
    "# Set to False when you are ready to use the real MolForge model.\n",
    "DEMO_MODE = False\n",
    "# Nota: el 'device' s'ha detectat a la cel·la 0 i es passarà automàticament al decoder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca44691",
   "metadata": {},
   "source": [
    "## 2) Imports i comprovacions d'entorn\n",
    "L'entorn ja ha estat creat amb `environment.yml`. Aquí només comprovem la disponibilitat de **RDKit** i **SELFIES** per informar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b782e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Core imports\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "import math\n",
    "\n",
    "# RDKit\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import AllChem, MACCSkeys, rdMolDescriptors as rdDesc\n",
    "    from rdkit import DataStructs\n",
    "    RDKit_OK = True\n",
    "except Exception as e:\n",
    "    RDKit_OK = False\n",
    "    print(\"RDKit not available. Please install RDKit (conda recommended): conda install -c rdkit rdkit\")\n",
    "\n",
    "# Avalon (optional; only if you intend to use Avalon fingerprints)\n",
    "try:\n",
    "    from rdkit.Avalon import pyAvalonTools as avalon\n",
    "    AVALON_OK = True\n",
    "except Exception:\n",
    "    AVALON_OK = False\n",
    "\n",
    "# SELFIES (optional; only if OUTPUT_REPR='SELFIES')\n",
    "try:\n",
    "    import selfies as sf\n",
    "    SELFIES_OK = True\n",
    "except Exception:\n",
    "    SELFIES_OK = False\n",
    "\n",
    "print(\"RDKit_OK:\", RDKit_OK, \"| AVALON_OK:\", AVALON_OK, \"| SELFIES_OK:\", SELFIES_OK)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4323e2cc",
   "metadata": {},
   "source": [
    "## 3) Helpers — parsing, canonització i conversió SELFIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b521a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# Helper functions (parsing, canonicalization, selfies)\n",
    "# ------------------------------\n",
    "\n",
    "def to_mol(smiles: str):\n",
    "    \"\"\"Parse SMILES into an RDKit Mol with sanitization; return None on failure.\"\"\"\n",
    "    if not RDKit_OK:\n",
    "        return None\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles, sanitize=True)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        Chem.SanitizeMol(mol)\n",
    "        return mol\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def canon_smiles(mol, isomeric: bool = True) -> str:\n",
    "    \"\"\"Return canonical SMILES (isomeric if requested).\"\"\"\n",
    "    if not RDKit_OK or mol is None:\n",
    "        return \"\"\n",
    "    return Chem.MolToSmiles(mol, isomericSmiles=isomeric, canonical=True)\n",
    "\n",
    "def selfies_to_smiles(s: str) -> str:\n",
    "    \"\"\"Convert SELFIES -> SMILES if selfies is installed; otherwise return input.\"\"\"\n",
    "    if not SELFIES_OK:\n",
    "        return s\n",
    "    try:\n",
    "        return sf.decoder(s)\n",
    "    except Exception:\n",
    "        return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c731599",
   "metadata": {},
   "source": [
    "## 4) Fingerprints RDKit — definicions i codi\n",
    "Aquí construïm totes les huelles que farem servir com a **entrada** del model i també per **avaluar** (Tc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b935081",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class FPResult:\n",
    "    kind: str           # name\n",
    "    obj: Any            # RDKit ExplicitBitVect or UIntSparseIntVect\n",
    "    is_sparse: bool\n",
    "    nbits: Optional[int] = None\n",
    "\n",
    "def morgan_hashed(mol, radius: int, nBits: int, useFeatures: bool = False) -> FPResult:\n",
    "    bv = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=nBits, useFeatures=useFeatures)\n",
    "    kind = f\"{'FCFP' if useFeatures else 'ECFP'}{2*radius}\"\n",
    "    return FPResult(kind=kind, obj=bv, is_sparse=False, nbits=nBits)\n",
    "\n",
    "def morgan_sparse(mol, radius: int) -> FPResult:\n",
    "    siv = AllChem.GetMorganFingerprint(mol, radius=radius)  # UIntSparseIntVect (counts)\n",
    "    kind = \"AEs\" if radius == 1 else f\"MorganSparse_r{radius}\"\n",
    "    return FPResult(kind=kind, obj=siv, is_sparse=True)\n",
    "\n",
    "def tt_sparse(mol) -> FPResult:\n",
    "    vec = rdDesc.GetTopologicalTorsionFingerprintAsIntVect(mol)\n",
    "    return FPResult(kind=\"TT\", obj=vec, is_sparse=True)\n",
    "\n",
    "def tt_hashed(mol, nBits: int) -> FPResult:\n",
    "    bv = rdDesc.GetHashedTopologicalTorsionFingerprintAsBitVect(mol, nBits=nBits)\n",
    "    return FPResult(kind=\"HashTT\", obj=bv, is_sparse=False, nbits=nBits)\n",
    "\n",
    "def ap_sparse(mol) -> FPResult:\n",
    "    vec = rdDesc.GetAtomPairFingerprint(mol)\n",
    "    return FPResult(kind=\"AP\", obj=vec, is_sparse=True)\n",
    "\n",
    "def ap_hashed(mol, nBits: int) -> FPResult:\n",
    "    bv = rdDesc.GetHashedAtomPairFingerprintAsBitVect(mol, nBits=nBits)\n",
    "    return FPResult(kind=\"HashAP\", obj=bv, is_sparse=False, nbits=nBits)\n",
    "\n",
    "def rdk4(mol, branchedPaths: bool = True, nBits: int = 2048) -> FPResult:\n",
    "    bv = Chem.RDKFingerprint(mol, fpSize=nBits, minPath=2, maxPath=4, branchedPaths=branchedPaths)\n",
    "    return FPResult(kind=\"RDK4\" if branchedPaths else \"RDK4-L\", obj=bv, is_sparse=False, nbits=nBits)\n",
    "\n",
    "def avalon_fp(mol, nBits: int = 512) -> Optional[FPResult]:\n",
    "    if not AVALON_OK:\n",
    "        return None\n",
    "    bv = avalon.GetAvalonFP(mol, nBits=nBits)\n",
    "    return FPResult(kind=\"Avalon\", obj=bv, is_sparse=False, nbits=nBits)\n",
    "\n",
    "def maccs(mol) -> FPResult:\n",
    "    bv = MACCSkeys.GenMACCSKeys(mol)  # 167 bits\n",
    "    return FPResult(kind=\"MACCS\", obj=bv, is_sparse=False, nbits=167)\n",
    "\n",
    "def pattern_fp(mol, nBits: int = 2048) -> FPResult:\n",
    "    bv = Chem.PatternFingerprint(mol, fpSize=nBits)\n",
    "    return FPResult(kind=\"PatternFP\", obj=bv, is_sparse=False, nbits=nBits)\n",
    "\n",
    "def layered_fp(mol, nBits: int = 2048) -> FPResult:\n",
    "    bv = Chem.LayeredFingerprint(mol, fpSize=nBits)\n",
    "    return FPResult(kind=\"LayeredFP\", obj=bv, is_sparse=False, nbits=nBits)\n",
    "\n",
    "FP_ALIASES = {\n",
    "    \"ECFP0\": \"ECFP0\", \"ECFP2\": \"ECFP2\", \"ECFP4\": \"ECFP4\",\n",
    "    \"FCFP2\": \"FCFP2\", \"FCFP4\": \"FCFP4\",\n",
    "    \"AEs\": \"AEs\",\n",
    "    \"TT\": \"TT\", \"HashTT\": \"HashTT\",\n",
    "    \"AP\": \"AP\", \"HashAP\": \"HashAP\",\n",
    "    \"RDK4\": \"RDK4\", \"RDK4-L\": \"RDK4-L\",\n",
    "    \"Avalon\": \"Avalon\",\n",
    "    \"MACCS\": \"MACCS\",\n",
    "    \"PatternFP\": \"PatternFP\",\n",
    "    \"LayeredFP\": \"LayeredFP\",\n",
    "}\n",
    "\n",
    "DEFAULT_EVAL_FPS = [\n",
    "    \"ECFP0\", \"ECFP2\", \"ECFP4\", \"FCFP2\", \"FCFP4\",\n",
    "    \"AEs\", \"TT\", \"HashTT\", \"AP\", \"HashAP\",\n",
    "    \"RDK4\", \"RDK4-L\", \"Avalon\", \"MACCS\", \"PatternFP\"\n",
    "]\n",
    "\n",
    "def compute_fp(mol, fp_name: str, nBits: int = 2048) -> FPResult:\n",
    "    name = FP_ALIASES.get(fp_name, fp_name)\n",
    "    if name == \"ECFP0\":\n",
    "        return morgan_hashed(mol, radius=0, nBits=nBits, useFeatures=False)\n",
    "    if name == \"ECFP2\":\n",
    "        return morgan_hashed(mol, radius=1, nBits=nBits, useFeatures=False)\n",
    "    if name == \"ECFP4\":\n",
    "        return morgan_hashed(mol, radius=2, nBits=nBits, useFeatures=False)\n",
    "    if name == \"FCFP2\":\n",
    "        return morgan_hashed(mol, radius=1, nBits=nBits, useFeatures=True)\n",
    "    if name == \"FCFP4\":\n",
    "        return morgan_hashed(mol, radius=2, nBits=nBits, useFeatures=True)\n",
    "    if name == \"AEs\":\n",
    "        return morgan_sparse(mol, radius=1)\n",
    "    if name == \"TT\":\n",
    "        return tt_sparse(mol)\n",
    "    if name == \"HashTT\":\n",
    "        return tt_hashed(mol, nBits=nBits)\n",
    "    if name == \"AP\":\n",
    "        return ap_sparse(mol)\n",
    "    if name == \"HashAP\":\n",
    "        return ap_hashed(mol, nBits=nBits)\n",
    "    if name == \"RDK4\":\n",
    "        return rdk4(mol, branchedPaths=True, nBits=nBits)\n",
    "    if name == \"RDK4-L\":\n",
    "        return rdk4(mol, branchedPaths=False, nBits=nBits)\n",
    "    if name == \"Avalon\":\n",
    "        res = avalon_fp(mol, nBits=512)\n",
    "        if res is None:\n",
    "            raise RuntimeError(\"Avalon requested but Avalon toolkit is not available.\")\n",
    "        return res\n",
    "    if name == \"MACCS\":\n",
    "        return maccs(mol)\n",
    "    if name == \"PatternFP\":\n",
    "        return pattern_fp(mol, nBits=nBits)\n",
    "    if name == \"LayeredFP\":\n",
    "        return layered_fp(mol, nBits=nBits)\n",
    "    raise ValueError(f\"Unknown fingerprint: {fp_name}\")\n",
    "\n",
    "def fp_to_tokens(fp: FPResult) -> List[int]:\n",
    "    \"\"\"Map an RDKit fingerprint to token IDs for a Transformer.\n",
    "\"\n",
    "    \"- hashed bit vectors: return active bit indices\n",
    "\"\n",
    "    \"- sparse vectors: return explicit keys, repeated by count (multiset)\n",
    "\"\n",
    "    \"\"\"\"\n",
    "    if fp.is_sparse:\n",
    "        elems = fp.obj.GetNonzeroElements()  # dict[id] = count\n",
    "        toks = []\n",
    "        for k, c in elems.items():\n",
    "            toks.extend([int(k)] * int(c))\n",
    "        toks.sort()\n",
    "        return toks\n",
    "    else:\n",
    "        on_bits = list(fp.obj.GetOnBits())\n",
    "        return sorted(on_bits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d09ac7",
   "metadata": {},
   "source": [
    "## 5) Mètriques — Tc, breakdown i estadístics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# Similarity & metrics\n",
    "# ------------------------------\n",
    "\n",
    "def tanimoto(fp_a: FPResult, fp_b: FPResult) -> float:\n",
    "    return DataStructs.TanimotoSimilarity(fp_a.obj, fp_b.obj)\n",
    "\n",
    "def percentile(vals, q: float):\n",
    "    if not vals:\n",
    "        return float(\"nan\")\n",
    "    v = sorted(vals)\n",
    "    k = min(max(int(round((q/100.0)*(len(v)-1))), 0), len(v)-1)\n",
    "    return v[k]\n",
    "\n",
    "def cdf_threshold(vals, p: float = 0.01):\n",
    "    if not vals:\n",
    "        return float(\"nan\")\n",
    "    v = sorted(vals)\n",
    "    idx = max(int(math.floor(p * (len(v)-1))), 0)\n",
    "    return v[idx]\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class BreakdownCounts:\n",
    "    string_exact: int = 0\n",
    "    stereo_only: int = 0\n",
    "    no_canonical: int = 0\n",
    "    invalid: int = 0\n",
    "    other_mismatch: int = 0\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"string_exact\": self.string_exact,\n",
    "            \"stereo_only\": self.stereo_only,\n",
    "            \"no_canonical\": self.no_canonical,\n",
    "            \"invalid\": self.invalid,\n",
    "            \"other_mismatch\": self.other_mismatch,\n",
    "        }\n",
    "\n",
    "def classify_pair(gt_smiles: str, pred_str: str, output_repr: str = \"SMILES\"):\n",
    "    \"\"\"Classify prediction outcome and return (category, canon_gt_iso, canon_pred_iso).\"\"\"\n",
    "    gt_m = to_mol(gt_smiles)\n",
    "    gt_iso = canon_smiles(gt_m, isomeric=True)\n",
    "\n",
    "    if output_repr.upper() == \"SELFIES\":\n",
    "        pred_smiles = selfies_to_smiles(pred_str)\n",
    "    else:\n",
    "        pred_smiles = pred_str\n",
    "\n",
    "    pred_m = to_mol(pred_smiles)\n",
    "    if pred_m is None:\n",
    "        return \"invalid\", gt_iso, \"\"\n",
    "\n",
    "    pred_iso = canon_smiles(pred_m, isomeric=True)\n",
    "\n",
    "    # String-exact (isomeric)\n",
    "    if pred_iso == gt_iso:\n",
    "        return \"string_exact\", gt_iso, pred_iso\n",
    "\n",
    "    # Stereo-only (non-isomeric match)\n",
    "    gt_noniso = canon_smiles(gt_m, isomeric=False)\n",
    "    pred_noniso = canon_smiles(pred_m, isomeric=False)\n",
    "    if gt_noniso == pred_noniso:\n",
    "        return \"stereo_only\", gt_iso, pred_iso\n",
    "\n",
    "    # No-canonical (Tc==1.0 wrt Morgan sparse r=1 but strings differ)\n",
    "    fp_gt = morgan_sparse(gt_m, radius=1)\n",
    "    fp_pd = morgan_sparse(pred_m, radius=1)\n",
    "    if tanimoto(fp_gt, fp_pd) >= 1.0 - 1e-12:\n",
    "        return \"no_canonical\", gt_iso, pred_iso\n",
    "\n",
    "    return \"other_mismatch\", gt_iso, pred_iso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ab3a3",
   "metadata": {},
   "source": [
    "## 6) MolForge Decoder — adaptador\n",
    "Aquesta classe encapsula la càrrega i la decodificació.\n",
    "**Assumpció**: MolForge ja és instal·lable (`import molforge`).\n",
    "Quan tinguis el repo/config llest, implementa `load()` i `predict_batch()` segons l'API real i assegura que el model es **mou al `device` detectat** (`.to(self.device)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ee712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MolForgeDecoder:\n",
    "    def __init__(self, model_name: str, checkpoint: Optional[str], device: str = \"cpu\",\n",
    "                 tokenizer_vocab_json: Optional[str] = None, output_repr: str = \"SMILES\",\n",
    "                 demo_mode: bool = False):\n",
    "        self.model_name = model_name\n",
    "        self.checkpoint = checkpoint\n",
    "        self.device = device\n",
    "        self.tokenizer_vocab_json = tokenizer_vocab_json\n",
    "        self.output_repr = output_repr\n",
    "        self.demo_mode = demo_mode\n",
    "        self._model = None\n",
    "        self._tokenizer = None\n",
    "\n",
    "    def load(self):\n",
    "        if self.demo_mode:\n",
    "            self._model = object()  # mark as 'loaded'\n",
    "            return\n",
    "        # TODO: replace with real MolForge API\n",
    "        try:\n",
    "            import importlib\n",
    "            importlib.import_module(\"molforge\")\n",
    "            # Example pseudo-code:\n",
    "            # from molforge.models import load_model, load_tokenizer\n",
    "            # self._model = load_model(self.model_name, self.checkpoint, device=self.device)\n",
    "            # self._tokenizer = load_tokenizer(self.model_name, vocab_json=self.tokenizer_vocab_json)\n",
    "            self._model = object()\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"MolForge not found. Install the repo and adapt MolForgeDecoder.load().\") from e\n",
    "\n",
    "    def predict_batch(self, list_of_token_lists: List[List[int]], gt_smiles: Optional[List[str]] = None) -> List[str]:\n",
    "        if self._model is None:\n",
    "            raise RuntimeError(\"Decoder not loaded. Call load().\")\n",
    "        if self.demo_mode:\n",
    "            # In demo: echo canonical SMILES of the GT (if provided), otherwise return empty strings\n",
    "            out = []\n",
    "            if gt_smiles is None:\n",
    "                return [\"\" for _ in list_of_token_lists]\n",
    "            for s in gt_smiles:\n",
    "                m = to_mol(s)\n",
    "                out.append(canon_smiles(m, isomeric=True))\n",
    "            return out\n",
    "        # TODO: replace with real generation call\n",
    "        raise NotImplementedError(\"Implement MolForge decoding (model.generate/decode) for your repo setup.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefdc7be",
   "metadata": {},
   "source": [
    "## 7) Funció principal — avaluació end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47120f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_molforge(\n",
    "    smiles_list: List[str],\n",
    "    input_fp: str = \"ECFP4\",\n",
    "    output_repr: str = \"SMILES\",\n",
    "    molforge_model_name: str = \"ecfp4_to_smiles\",\n",
    "    molforge_checkpoint: Optional[str] = None,\n",
    "    eval_fps: Optional[List[str]] = None,\n",
    "    device: str = \"cpu\",\n",
    "    tokenizer_vocab_json: Optional[str] = None,\n",
    "    hashed_nbits: int = 2048,\n",
    "    return_predictions: bool = True,\n",
    "    use_multi_fp: bool = True,\n",
    "    single_eval_fp: str = \"ECFP4\",\n",
    "    demo_mode: bool = False,\n",
    "):\n",
    "    \"\"\"End-to-end evaluation mirroring MolForge paper metrics.\n",
    "\"\n",
    "    \"Returns a dict with breakdown counts, per-FP stats, and averages.\n",
    "\"\n",
    "    \"\"\"\"\n",
    "    if eval_fps is None:\n",
    "        eval_fps = list(DEFAULT_EVAL_FPS) if use_multi_fp else [single_eval_fp]\n",
    "\n",
    "    # 1) Parse GT molecules and build *input* fingerprints -> tokens\n",
    "    gt_mols = [to_mol(s) for s in smiles_list]\n",
    "    input_tokens_batch: List[List[int]] = []\n",
    "    for m in gt_mols:\n",
    "        if m is None:\n",
    "            input_tokens_batch.append([])  # keep alignment\n",
    "            continue\n",
    "        fp = compute_fp(m, input_fp, nBits=hashed_nbits)\n",
    "        toks = fp_to_tokens(fp)\n",
    "        input_tokens_batch.append(toks)\n",
    "\n",
    "    # 2) Decode with MolForge\n",
    "    decoder = MolForgeDecoder(\n",
    "        model_name=molforge_model_name,\n",
    "        checkpoint=molforge_checkpoint,\n",
    "        device=device,\n",
    "        tokenizer_vocab_json=tokenizer_vocab_json,\n",
    "        output_repr=output_repr,\n",
    "        demo_mode=demo_mode,\n",
    "    )\n",
    "    decoder.load()\n",
    "    predictions = decoder.predict_batch(input_tokens_batch, gt_smiles=smiles_list)\n",
    "\n",
    "    # 3) Breakdown classification\n",
    "    breakdown = BreakdownCounts()\n",
    "    validity_mask: List[bool] = []\n",
    "    for gt, pred in zip(smiles_list, predictions):\n",
    "        cat, _, canon_pred = classify_pair(gt, pred, output_repr=output_repr)\n",
    "        if cat == \"string_exact\":\n",
    "            breakdown.string_exact += 1; validity_mask.append(True)\n",
    "        elif cat == \"stereo_only\":\n",
    "            breakdown.stereo_only += 1; validity_mask.append(True)\n",
    "        elif cat == \"no_canonical\":\n",
    "            breakdown.no_canonical += 1; validity_mask.append(True)\n",
    "        elif cat == \"invalid\":\n",
    "            breakdown.invalid += 1; validity_mask.append(False)\n",
    "        else:\n",
    "            breakdown.other_mismatch += 1; validity_mask.append(bool(canon_pred))\n",
    "\n",
    "    total_valid = sum(1 for v in validity_mask if v)\n",
    "\n",
    "    # 4) Multi-fingerprint Tc computation\n",
    "    per_fp_tc = {fpn: [] for fpn in eval_fps}\n",
    "    top1_counts = {fpn: 0 for fpn in eval_fps}\n",
    "\n",
    "    for (gt, pred, is_valid) in zip(smiles_list, predictions, validity_mask):\n",
    "        if not is_valid:\n",
    "            continue\n",
    "        gt_m = to_mol(gt)\n",
    "        pred_m = to_mol(pred if output_repr.upper() == \"SMILES\" else selfies_to_smiles(pred))\n",
    "        if gt_m is None or pred_m is None:\n",
    "            continue\n",
    "        for fp_name in eval_fps:\n",
    "            gt_fp = compute_fp(gt_m, fp_name, nBits=hashed_nbits)\n",
    "            pd_fp = compute_fp(pred_m, fp_name, nBits=hashed_nbits)\n",
    "            tc = tanimoto(gt_fp, pd_fp)\n",
    "            per_fp_tc[fp_name].append(float(tc))\n",
    "            if tc >= 1.0 - 1e-12:\n",
    "                top1_counts[fp_name] += 1\n",
    "\n",
    "    # 5) Aggregate stats per FP\n",
    "    eval_stats = {}\n",
    "    for fp_name, tcs in per_fp_tc.items():\n",
    "        if tcs:\n",
    "            eval_stats[fp_name] = {\n",
    "                \"top1\": top1_counts[fp_name] / max(total_valid, 1.0),\n",
    "                \"mean_tc\": float(sum(tcs) / len(tcs)),\n",
    "                \"p01_threshold\": float(cdf_threshold(tcs, p=0.01)),\n",
    "                \"p50\": float(percentile(tcs, 50)),\n",
    "                \"p90\": float(percentile(tcs, 90)),\n",
    "                \"p99\": float(percentile(tcs, 99)),\n",
    "                \"n_pairs\": int(len(tcs)),\n",
    "            }\n",
    "        else:\n",
    "            eval_stats[fp_name] = {\n",
    "                \"top1\": float('nan'), \"mean_tc\": float('nan'),\n",
    "                \"p01_threshold\": float('nan'), \"p50\": float('nan'),\n",
    "                \"p90\": float('nan'), \"p99\": float('nan'), \"n_pairs\": 0\n",
    "            }\n",
    "\n",
    "    # 6) Mean across eval FPs\n",
    "    valid_fps = [fp for fp, st in eval_stats.items() if not math.isnan(st[\"top1\"])]\n",
    "    top1_mean = float(sum(eval_stats[fp][\"top1\"] for fp in valid_fps) / max(len(valid_fps), 1))\n",
    "    mean_tc_mean = float(sum(eval_stats[fp][\"mean_tc\"] for fp in valid_fps) / max(len(valid_fps), 1))\n",
    "\n",
    "    out = {\n",
    "        \"n\": len(smiles_list),\n",
    "        \"breakdown\": breakdown.to_dict(),\n",
    "        \"eval_fps\": eval_stats,\n",
    "        \"eval_fps_average\": {\n",
    "            \"top1_mean_over_fps\": top1_mean,\n",
    "            \"mean_tc_mean_over_fps\": mean_tc_mean,\n",
    "            \"n_eval_fps\": len(valid_fps),\n",
    "        },\n",
    "        \"predictions\": predictions,\n",
    "    }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2398f6",
   "metadata": {},
   "source": [
    "## 8) Executar — prova ràpida amb els SMILES dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Execute evaluation with current INPUTS\n",
    "if not RDKit_OK:\n",
    "    raise RuntimeError(\"RDKit not available. Please install RDKit to run this notebook.\")\n",
    "\n",
    "eval_fps = None  # use default ~15 if USE_MULTI_FP, else SINGLE_EVAL_FP\n",
    "if not USE_MULTI_FP:\n",
    "    eval_fps = [SINGLE_EVAL_FP]\n",
    "\n",
    "results = evaluate_molforge(\n",
    "    smiles_list=SMILES_LIST,\n",
    "    input_fp=INPUT_FP,\n",
    "    output_repr=OUTPUT_REPR,\n",
    "    molforge_model_name=MODEL_NAME,\n",
    "    molforge_checkpoint=MOLFORGE_CHECKPOINT,\n",
    "    eval_fps=eval_fps,\n",
    "    device=device,\n",
    "    tokenizer_vocab_json=TOKENIZER_VOCAB_JSON,\n",
    "    hashed_nbits=HASHED_NBITS,\n",
    "    return_predictions=True,\n",
    "    use_multi_fp=USE_MULTI_FP,\n",
    "    single_eval_fp=SINGLE_EVAL_FP,\n",
    "    demo_mode=DEMO_MODE,\n",
    ")\n",
    "\n",
    "print(\"# Inputs:\")\n",
    "print(\"n =\", results[\"n\"]) \n",
    "print(\"input_fp =\", INPUT_FP, \"| output_repr =\", OUTPUT_REPR)\n",
    "print(\"demo_mode =\", DEMO_MODE)\n",
    "print(\"\\n# Breakdown:\")\n",
    "for k, v in results[\"breakdown\"].items():\n",
    "    print(f\"{k:14s} : {v}\")\n",
    "print(\"\\n# Eval FPS Average:\")\n",
    "for k, v in results[\"eval_fps_average\"].items():\n",
    "    print(f\"{k:24s}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9f0df4",
   "metadata": {},
   "source": [
    "## 9) Taula de mètriques per fingerprint d'avaluació"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e424e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from caas_jupyter_tools import display_dataframe_to_user\n",
    "\n",
    "df = pd.DataFrame(results[\"eval_fps\"]).T\n",
    "df = df[[\"n_pairs\", \"top1\", \"mean_tc\", \"p01_threshold\", \"p50\", \"p90\", \"p99\"]]\n",
    "df.sort_values(by=[\"top1\", \"mean_tc\"], ascending=False, inplace=True)\n",
    "\n",
    "display_dataframe_to_user(\"MolForge per-FP metrics\", df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebdf775",
   "metadata": {},
   "source": [
    "## 10) Gràfic opcional — histograma de Tc per a una huella d'avaluació\n",
    "Selecciona una fingerprint de `results['eval_fps']` per visualitzar la distribució de Tc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose an FP present in results to plot distribution\n",
    "fp_to_plot = SINGLE_EVAL_FP if not USE_MULTI_FP else (\"ECFP4\" if \"ECFP4\" in results[\"eval_fps\"] else list(results[\"eval_fps\"].keys())[0])\n",
    "\n",
    "# Recompute per-pair Tc list for the chosen FP to plot\n",
    "tcs = []\n",
    "\n",
    "for gt, pred in zip(SMILES_LIST, results[\"predictions\"]):\n",
    "    gt_m = to_mol(gt); pred_m = to_mol(pred if OUTPUT_REPR.upper()==\"SMILES\" else selfies_to_smiles(pred))\n",
    "    if gt_m is None or pred_m is None:\n",
    "        continue\n",
    "    tc = tanimoto(compute_fp(gt_m, fp_to_plot, nBits=HASHED_NBITS), compute_fp(pred_m, fp_to_plot, nBits=HASHED_NBITS))\n",
    "    tcs.append(tc)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(tcs, bins=10)\n",
    "plt.title(f\"Tc distribution for {fp_to_plot}\")\n",
    "plt.xlabel(\"Tc (Tanimoto)\"); plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc229fa",
   "metadata": {},
   "source": [
    "## 11) Notes ràpides d'ús\n",
    "- RDKit i MolForge ja estan instal·lats via entorn.\n",
    "- Usa el `device` detectat per moure el model a GPU/CPU.\n",
    "- No cal repetir instruccions d'instal·lació aquí."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}